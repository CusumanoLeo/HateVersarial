{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdf7b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d78ec",
   "metadata": {},
   "source": [
    "### Using unicode database for homoglyphs\n",
    "https://www.unicode.org/reports/tr39/ :\n",
    "\n",
    "**Summary**\n",
    "Because Unicode contains such a large number of characters and incorporates the varied writing systems of the world, incorrect usage can expose programs or systems to possible security attacks. This document specifies mechanisms that can be used to detect possible security problems.\n",
    "\n",
    "**Status**\n",
    "This document has been reviewed by Unicode members and other interested parties, and has been approved for publication by the Unicode Consortium. This is a stable document and may be used as reference material or cited as a normative reference by other specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a433956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_homoglyph_map():\n",
    "    url = \"https://www.unicode.org/Public/security/latest/confusables.txt\" \n",
    "    response = requests.get(url) # Fetch the confusables data\n",
    "    raw_text = response.text     # Get the text content\n",
    "\n",
    "    homoglyph_map = defaultdict(list) \n",
    "\n",
    "    for line in raw_text.splitlines():\n",
    "        if line.startswith('#') or not line.strip(): # Skip comments and empty lines\n",
    "            continue\n",
    "        try:\n",
    "            src_hex, target_hex, *_ = line.split(';') # \n",
    "            src_char = chr(int(src_hex.strip(), 16))\n",
    "            target_chars = ''.join([chr(int(h, 16)) for h in target_hex.strip().split()])\n",
    "\n",
    "            # We only want visually similar substitutions that map to 1 character\n",
    "            if len(src_char) == 1 and len(target_chars) == 1:\n",
    "                ascii_base = target_chars.lower()\n",
    "                if ascii_base.isascii() and ascii_base.isalnum():\n",
    "                    homoglyph_map[ascii_base].append(src_char)\n",
    "        except Exception as e:\n",
    "            continue  # skip malformed lines\n",
    "\n",
    "    # Convert defaultdict to normal dict and deduplicate entries\n",
    "    homoglyph_map = {k: list(set(v)) for k, v in homoglyph_map.items()}\n",
    "\n",
    "    return homoglyph_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cbb72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a â†’ ['ğ”', 'ğ—”', 'ğš¨', 'Ğ°', 'ğ”„', 'ğ˜¼', 'ğ˜ˆ', 'ğ›‚', 'Î‘', 'ğŠ ', 'ğ“', 'ğ–†', 'Ğ', 'ğ•¬', 'ğ€', 'ğª', 'ğ–º', 'ğ', 'ğ™–', 'ğ‘¨', 'ğ’¶', 'ğ– ', 'ğš', 'ê“®', 'É‘', 'âº', 'ğ–½€', 'ğ™°', 'ğ’œ', 'ğ’‚', 'á—…', 'ğ•’', 'ï¼¡', 'ğ“ª', 'ğšŠ', '\\U0001ccd6', 'ğœ¶', 'ğ—®', 'ï½', 'ğ›¢', 'ğ°', 'ğ–', 'Î±', 'ğ”¸', 'áª', 'ğ˜¢', 'ğ›¼', 'ğ´', 'ğ‘', 'ğœœ']\n",
      "e â†’ ['ğ›¦', 'â„¯', 'ğ—²', 'ğ•°', 'ğ‘’', 'ğ–¤', 'â´¹', 'Î•', 'ğ‘¢®', 'ğ‘¬', 'â„®', 'ğ™´', 'â‹¿', 'ğ–¾', 'ğ—˜', 'ğœ ', 'ï¼¥', 'ğ”¼', 'ğ“®', 'ê¬²', 'ğ”¢', 'ğ“”', 'Ğ•', 'ğ”ˆ', 'ğ˜¦', 'ï½…', 'ğ‘¢¦', 'ğš¬', 'ğš', 'â…‡', 'ğ¸', 'ğ™€', 'ğ–Š', 'ğ„', 'ğ', 'ğŠ†', 'ğ”', '\\U0001ccda', 'ğ˜Œ', 'Ğµ', 'â„°', 'ğš', 'ğ’†', 'ğ•–', 'ê“°', 'á¬', 'Ò½', 'ğ™š']\n",
      "i â†’ ['ğ—¶', 'ï½‰', 'Î¹', 'ê™‡', 'ğœ¾', 'Ë›', 'ğ¢', 'Ó', 'ğ“²', 'ğ’¾', 'ğ™', 'ğ˜ª', 'á¾¾', 'Ñ–', 'ğ—‚', 'ğ‘–', 'ğ’Š', 'ğš¤', 'â³', 'É©', 'Ä±', 'Éª', 'ğ•š', 'ğ‘£ƒ', 'ğ–', 'ğš’', 'ğ²', 'ğ”¦', 'ê­µ', 'á¥', 'â„¹', 'ğ›Š', 'â…°', 'ğœ„', 'â…ˆ', 'ğ¸', 'Íº']\n",
      "o â†’ ['à¥¦', 'ğš¶', 'ğ˜–', 'â²Ÿ', 'ï®ª', 'ğ„', 'ï»¬', 'ğº„', 'ğœª', 'ğŠ’', 'à±¦', 'ğ™¾', 'ï»ª', 'à»', 'Ğ', 'Û•', 'ï®§', 'Ûµ', 'ğ—¢', 'Ğ¾', 'ğ“ª', 'à¹', 'ğ• ', 'ğ›°', 'ğ˜°', 'à²‚', 'ğ‘£—', 'ê¬½', 'à´ ', 'ğ¤', 'Õ•', 'ğ•º', 'ï»©', 'à³¦', 'ï®«', '0', 'ğ‘£ˆ', 'ğ¨', 'ğ“‚', 'ğŸ˜', 'ğŸ¯°', 'à°‚', 'á´‘', 'ğ', 'ğ’', 'ğ‘¶', 'ğ›”', 'ğ—¼', '\\U0001ccf0', 'à¶‚', 'ğ“¸', 'ğ›', 'ï®¦', 'ğŸ', 'ğˆ', 'ğŸ¬', 'ğ—ˆ', 'á€', 'ğ‘“', 'ğ¬', 'Ö…', 'ğ¾', 'ï½', 'à­¦', 'à§¦', 'ê“³', 'ğš˜', 'Û', 'ğ’ª', 'ğ‘£ ', 'áƒ¿', 'ğ™Š', 'ğŸ¶', 'à©¦', 'ğŠ«', 'ğ“', 'ğ¼', 'ÎŸ', 'àµ¦', '\\U0001cce4', 'ß€', 'á‹', 'à´‚', 'Ïƒ', 'Ù‡', 'ï»«', 'ğŸ¢', 'ğ¹¤', 'à«¦', 'ğ–®', 'ï®¨', 'ğœ', 'ğ”¬', 'ğ‘œ', 'ğ¸¤', 'ğ–”', 'ğ‚', 'ğ•†', 'â„´', 'âµ”', 'à¬ ', 'ã€‡', 'ï®¬', 'à¯¦', '×¡', 'ï®­', 'â²', 'ğœŠ', 'ï¼¯', 'á´', 'ğ”’', 'ğ‘¢µ', 'ğ”–', 'ğ„', 'ğ‘‚', 'ğ™¤', 'Ù¥', 'Î¿', 'ï®©', 'á€', 'ğ', 'Ú¾', 'ğ¸']\n",
      "s â†’ ['ğ‘†', 'áš', 'Ğ…', 'ğ•Š', 'ğ˜€', 'ğ”°', 'ğ’”', 'ğ“¼', 'Ñ•', 'ğŠ–', 'ğ‘º', 'ğ”–', 'ğ“¢', 'ğ˜š', 'ğ‘£', '\\U0001cce8', 'ğ ', 'ğ–˜', 'ğ’', 'á•', 'ğ‘ ', 'ğ–²', 'Õ', 'ğšœ', 'ğ‘ˆ', 'ê“¢', 'ğ•¾', 'êœ±', 'ğ—Œ', 'ğ˜´', 'ğ™¨', 'ğ’®', 'ğ™', 'ğš‚', 'ğ¬', 'ğ“ˆ', 'ê®ª', 'ğ–¼º', 'ğ•¤', 'ï½“', 'ï¼³', 'ğ—¦', 'Æ½']\n",
      "t â†’ ['ğ•¿', 'ê“”', 'ğ­', 'ğ‘»', 'Î¤', 'ğ™', 'ğœ¯', 'ğ˜µ', 'ğ—§', 'ğ—', 'ğ–³', 'ğŠ±', 'ğŠ—', 'ğ•‹', 'ğ‘‡', 'ğ“‰', 'ğ˜', 'ğ©', 'ğ‘¡', 'ï¼´', 'ğ’•', 'ğ‘¢¼', 'ğ”±', 'Ğ¢', 'ğ˜›', 'ğš', 'ğšƒ', 'ğ“', 'â²¦', 'ğ£', 'ğ“£', 'ğš»', 'ğŒ•', 'ğ–™', 'ğ–¼Š', 'ğ’¯', 'ğ›µ', 'ğŸ¨', 'âŸ™', 'ğ™©', '\\U0001cce9', 'âŠ¤', 'á¢', 'ğ”—', 'ğ•¥', 'ğ“½']\n"
     ]
    }
   ],
   "source": [
    "# Some letters to test\n",
    "if __name__ == \"__main__\":\n",
    "    homoglyph_map = build_homoglyph_map()\n",
    "    for letter in ['a', 'e', 'i', 'o', 's', 't']:\n",
    "        print(f\"{letter} â†’ {homoglyph_map.get(letter, [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57e281",
   "metadata": {},
   "source": [
    "### Leetspeak perturbations\n",
    "\n",
    "https://pypi.org/project/pyleetspeak/\n",
    "\n",
    "This tool aims to counter new misinformation that emerges in social media platforms by providing a mechanism for simulating and generating leetspeak/word camouflaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyleetspeak\n",
    "# ! pip install pyphen\n",
    "# ! pip install keybert\n",
    "# ! pip install codetiming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668f19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyleetspeak.LeetSpeaker import LeetSpeaker\n",
    "from pyleetspeak.Leet_NER_generator import NER_data_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48abc650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I sp34k l3etsp3@k\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text_in = \"I speak leetspeak\"\n",
    "leeter = LeetSpeaker(\n",
    "    change_prb=0.8, change_frq=0.6, mode=\"basic\", seed=None, verbose=False\n",
    ")\n",
    "leet_result = leeter.text2leet(text_in)\n",
    "print(leet_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77ce8543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hate', 'hat3', 'h@te', 'h4t3', 'h4te', 'h@t3']\n"
     ]
    }
   ],
   "source": [
    "# All possible combinations\n",
    "leeter = LeetSpeaker(get_all_combs=True, mode=\"basic\")\n",
    "combinations = leeter.text2leet(\"hate\")\n",
    "print(combinations)  # list of strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f74851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean:     I hate you\n",
      "Augmented: 1 hat3 y0_\n",
      "---\n",
      "Clean:     Go back to your country\n",
      "Augmented: Go b@ck to your country\n",
      "---\n",
      "Clean:     You are disgusting\n",
      "Augmented: You @r3 d1sgust1ng\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "leeter = LeetSpeaker(\n",
    "    change_prb=0.6,     # probability of changing each char\n",
    "    change_frq=0.6,     # frequency across the whole string\n",
    "    mode=\"basic\",       # you can try \"intermediate\" or \"advanced\" too\n",
    "    seed=42,            # set for reproducibility\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "texts = [\n",
    "    \"I hate you\",\n",
    "    \"Go back to your country\",\n",
    "    \"You are disgusting\"\n",
    "]\n",
    "\n",
    "augmented_texts = [leeter.text2leet(t) for t in texts]\n",
    "\n",
    "for clean, aug in zip(texts, augmented_texts):\n",
    "    print(f\"Clean:     {clean}\")\n",
    "    print(f\"Augmented: {aug}\")\n",
    "    print(\"---\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
