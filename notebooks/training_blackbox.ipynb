{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of my notebook is to find a way to extract rationales (= justification a prediction) from data classified as \"toxic\".\n",
    "\n",
    "To do so, according to peer-reviewed methods, there are several options:\n",
    "\n",
    "1. Use the self-attention scores of the classifier as token importance (see Leo's work)\n",
    "2. Perturb or back-prop once the model is trained (IG, GradCAM, LIME, SHAP) -> **huge token-level noise & very slow for large dataset**\n",
    "3. Hard-selection \"rationalizing\" models (generator picks a sparse subset and predictor uses only it) -> **HEAVY!!! also generator often drops synthactic glue -> low recall**\n",
    "4. Supervised token-label models (fine-tune BERT with a second token-level BiLSTM/CRF head on HateXplain rationales) -> **fast, good F1, needs faithfulness regulariser (sparse annotion risk!!)**\n",
    "5. Masked-rational prediction (use an auxiliary loss: mask predicted rationale, ask model to reconstruct class from only those tokens -> encourages necessity & sufficiency) -> **robust F1, needs 2 forward passes per step**\n",
    "6. Semi-/Self-training (Teacher-student) -> Train on gold spans, predict on unlabelled data, keep high-confidence spans, retrain -> **quality hinges on initial extractor, risk of error amplification BUT works well when bootstrapped from a strong supervised extractor**\n",
    "7. LLM chain-of-thought extraction (prompt GPT-3.5/4 to highlight toxic words) -> **good human plausibility BUT license issues**\n",
    "\n",
    "### What makes a good rationale extractor:\n",
    "- faithfulness (if we delete the selected tokens, the modelâ€™s prediction should flip (comprehensiveness) and if we keep only the tokens, the prediction should stay (sufficiency))\n",
    "- granularity (need word- or sub-word spans, not whole sentences)\n",
    "- plausibility (human annotators should agree that the highlighted words look toxic)\n",
    "- training signal available (use HateXplain rationales labels)\n",
    "\n",
    "I will try 4 (for extractor) + 5 + 6 (and maybe 7 if i have time) => use a supervised multi-task BERT span-tagger (token classification head) regularised with a HardKuma selector, backed up by Integrated Gradients for sanity-checking. The steps are as follows:\n",
    "\n",
    "### 1. **SUPERVISED EXTRACTOR (token tagging):** Fine-tune multi-task BERT-base span-tagger with 2 heads:\n",
    "- sentence-level classification head (toxic vs. non-toxic binary classification) (cross-entropy)\n",
    "- token-level rationale tags (sigmoid for each sub-token)\n",
    "\n",
    "Use a multi-objective loss function to train the rationale extractor + classifier at the same time\n",
    "\n",
    "+ & use HardKuma = differentiable mechanism for selecting discrete tokens (like specific words) in a sentence while still allowing backpropagation. It was introduced by Bastings et al. (2020) in â€œInterpretable Neural Predictions with Differentiable Binary Variablesâ€.\n",
    "\n",
    "#### Evaluation & calibration:\n",
    "\n",
    "- Hold out 10 % of HateXplain for token-level metrics (IOU-F1, comprehensiveness, sufficiency â€“ ERASER toolkit) \n",
    "ACL Anthology\n",
    "- Choose the probability threshold that maximises dev token-F1; typical â‰ˆ 0.4.\n",
    "\n",
    "#### Generalisation check\n",
    "Test on the external Toxic-Span (SemEval-2021) set; you should still get â‰ˆ 0.46 F1 (Multi-task CRF baseline) \n",
    "\n",
    "### 2. **CONFIDENCE-FILTERED SELF-TRAINING:** Run the extractor on the generated posts (from Melina's generator). \n",
    "\n",
    "graph TD\n",
    "  A[Generated post] --> B(Rationale extractor)\n",
    "  B -->|mask| C{Toxic tokens}\n",
    "  C --> D[Homoglyph + leet transform]\n",
    "  A -->|context| E[Untouched tokens]\n",
    "  D --> F{Re-assemble text}\n",
    "  E --> F\n",
    "\n",
    "\n",
    "=> Report token-level F1, Sufficiency & Comprehensiveness (ERASER metrics)\n",
    "\n",
    "## Implementation tips:\n",
    "\n",
    "1. Sub-token aggregation - aggregate logits with max per original token to avoid partial masking.\n",
    "\n",
    "2. Sparsity without recall loss - tune Î»_len s.t. mean span length â‰ˆ 25 % of tokens; lower hurts precision, higher drops recall.\n",
    "\n",
    "3. Stop-word whitelist - never transform stop-words even if tagged (keeps syntax readable).\n",
    "\n",
    "4. Version control - export masks to JSON; downstream augmentation becomes a pure text-edit, reproducible for audits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import requests\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, get_linear_schedule_with_warmup, EarlyStoppingCallback, pipeline\n",
    "from transformers import AutoModel, PreTrainedTokenizerBase\n",
    "from pyleetspeak.LeetSpeaker import LeetSpeaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 13\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_classes_two = np.load('../Data/classes_two.npy', allow_pickle=True)\n",
    "data_classes = np.load('../Data/classes.npy', allow_pickle=True)\n",
    "\n",
    "with open('../Data/dataset.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "with open('../Data/post_id_divisions.json', 'r') as f:\n",
    "    split_ids = json.load(f)\n",
    "\n",
    "\n",
    "examples_binary = [\n",
    "    (\" \".join(dataset[k]['post_tokens']), label)\n",
    "    for k, label in zip(dataset.keys(), data_classes_two)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20148\n",
      "20148\n",
      "['<user>', 'i', 'am', 'bit', 'confused', 'coz', 'chinese', 'ppl', 'can', 'not', 'access', 'twitter', 'thn', 'how', 'this', 'ching', 'chong', 'using', 'it', 'i', 'think', 'he', 'pakistani', 'ðŸ¤”', 'ðŸ¤”', 'ðŸ¤”']\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "rationales = [\n",
    "    (dataset[k]['rationales'])\n",
    "    for k in dataset.keys()\n",
    "]\n",
    "\n",
    "posts = [\n",
    "    (dataset[k]['post_tokens'])\n",
    "    for k in dataset.keys()\n",
    "]\n",
    "\n",
    "print(len(posts))\n",
    "print(len(rationales))\n",
    "print(posts[3])\n",
    "print(rationales[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = []\n",
    "\n",
    "for k, v in dataset.items():\n",
    "    text = \" \".join(v['post_tokens']) \n",
    "    \n",
    "    # Use majority vote to decide the label\n",
    "    if 'annotators' in v and v['annotators']:\n",
    "        labels = [ann['label'] for ann in v['annotators']] # Get labels from annotators\n",
    "        label_counts = Counter(labels) \n",
    "        majority_label = label_counts.most_common(1)[0][0] # Get the most common label\n",
    "        examples.append((text, majority_label))\n",
    "\n",
    "label_counts = Counter(label for _, label in examples)\n",
    "total = sum(label_counts.values())\n",
    "label_percentages = {label: (count / total) * 100 for label, count in label_counts.items()}\n",
    "\n",
    "plt.bar(label_percentages.keys(), label_percentages.values())\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('Distribution of Labels (Percentage)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 20148\n",
      "Unanimous (all annotators agree): 9845 (48.86%)\n",
      "Two-label disagreement: 9384 (46.58%)\n",
      "Three-label disagreement: 919 (4.56%)\n",
      "Unanimous: 9845, Offensive vs Hatespeech: 3916, Normal vs Other: 5468, Skipped (3-label): 919\n"
     ]
    }
   ],
   "source": [
    "# RESOLVE DISAGREEMENT BETWEEN ANNOTATORS\n",
    "\n",
    "def compute_annotator_disagreement(dataset, verbose=False, return_top_n=0, plot=False):\n",
    "    \"\"\"\n",
    "    Compute the number of unique labels assigned by annotators for each post,\n",
    "    and optionally plot disagreement distribution.\n",
    "    \n",
    "    Args:\n",
    "        dataset (dict): Loaded JSON dataset\n",
    "        verbose (bool): Print summary stats\n",
    "        return_top_n (int): If >0, return top N most disagreed examples\n",
    "        plot (bool): If True, plot a histogram of disagreement levels\n",
    "\n",
    "    Returns:\n",
    "        disagreement_stats (list of tuples): (post_id, disagreement_count, label_counter)\n",
    "        top_disagreements (optional): top N posts with highest disagreement\n",
    "    \"\"\"\n",
    "    disagreement_stats = []\n",
    "\n",
    "    for post_id, content in dataset.items():\n",
    "        labels = [ann['label'] for ann in content.get('annotators', [])]\n",
    "        label_counter = Counter(labels)\n",
    "        disagreement_count = len(label_counter)\n",
    "        disagreement_stats.append((post_id, disagreement_count, label_counter))\n",
    "\n",
    "    if verbose:\n",
    "        total = len(disagreement_stats)\n",
    "        unanimous = sum(1 for _, c, _ in disagreement_stats if c == 1)\n",
    "        mild_disagreement = sum(1 for _, c, _ in disagreement_stats if c == 2)\n",
    "        full_disagreement = sum(1 for _, c, _ in disagreement_stats if c >= 3)\n",
    "\n",
    "        print(f\"Total examples: {total}\")\n",
    "        print(f\"Unanimous (all annotators agree): {unanimous} ({unanimous/total:.2%})\")\n",
    "        print(f\"Two-label disagreement: {mild_disagreement} ({mild_disagreement/total:.2%})\")\n",
    "        print(f\"Three-label disagreement: {full_disagreement} ({full_disagreement/total:.2%})\")\n",
    "\n",
    "    if plot:\n",
    "        disagreement_counts = [c for _, c, _ in disagreement_stats]\n",
    "        count_dist = Counter(disagreement_counts)\n",
    "        plt.bar(count_dist.keys(), count_dist.values(), color='gray')\n",
    "        plt.xlabel(\"Number of unique labels (Disagreement level)\")\n",
    "        plt.ylabel(\"Number of posts\")\n",
    "        plt.title(\"Annotator Disagreement Distribution\")\n",
    "        plt.xticks([1, 2, 3])\n",
    "        plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if return_top_n > 0:\n",
    "        top_disagreements = sorted(disagreement_stats, key=lambda x: -x[1])[:return_top_n]\n",
    "        return disagreement_stats, top_disagreements\n",
    "\n",
    "    return disagreement_stats\n",
    "\n",
    "def resolve_disagreements_custom(dataset, disagreement_stats):\n",
    "    resolved = []\n",
    "    counter_unanimous = 0\n",
    "    counter_hatespeech = 0\n",
    "    counter_off_normal = 0\n",
    "    counter_skipped = 0\n",
    "\n",
    "    for post_id, disagreement, label_counts in disagreement_stats:\n",
    "        if disagreement == 3:\n",
    "            counter_skipped += 1\n",
    "            continue  # skip level 3 disagreements\n",
    "\n",
    "        text = \" \".join(dataset[post_id]['post_tokens'])\n",
    "        labels = list(label_counts.elements())\n",
    "        label_set = set(label_counts.keys())\n",
    "\n",
    "        # Case 1: unanimous\n",
    "        if disagreement == 1:\n",
    "            counter_unanimous += 1\n",
    "            resolved_label = labels[0]\n",
    "\n",
    "        # Case 2: offensive vs hatespeech â†’ resolve as hatespeech\n",
    "        elif disagreement == 2 and label_set == {\"offensive\", \"hatespeech\"}:\n",
    "            counter_hatespeech += 1\n",
    "            resolved_label = \"hatespeech\"\n",
    "\n",
    "        # Case 3: normal vs offensive or normal vs hatespeech â†’ majority\n",
    "        else:\n",
    "            counter_off_normal += 1\n",
    "            resolved_label = Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "        resolved.append((text, resolved_label))\n",
    "\n",
    "    print(f\"Unanimous: {counter_unanimous}, Offensive vs Hatespeech: {counter_hatespeech}, Normal vs Other: {counter_off_normal}, Skipped (3-label): {counter_skipped}\")\n",
    "    return resolved\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "disagreement_stats, top_disagreements = compute_annotator_disagreement(dataset, verbose=True, return_top_n=5, plot=False)\n",
    "\n",
    "\n",
    "resolved_examples_custom = resolve_disagreements_custom(dataset, disagreement_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGE_MODE = \"union\" # other possibilities: \"majority\" -> but may drop rare buzt valid toxic terms / else: intersection (POOR COVERAGE, TOO STRICT!!!!!!!!!!)\n",
    "\n",
    "def merge_rationales(masks, n_tokens, mode=\"union\"):\n",
    "    \"\"\"\n",
    "    masks    : List[List[int]] (length 0â€“3, possibly wrong sizes)\n",
    "    n_tokens : int  = len(post['post_tokens'])\n",
    "    Returns   : merged mask (list[int]) or None if no valid annotator\n",
    "    \"\"\"\n",
    "    # Keep only masks whose length matches the post\n",
    "    arrs = [np.array(m) for m in masks if len(m) == n_tokens]\n",
    "\n",
    "    if len(arrs) == 0:\n",
    "        return None                      # no reliable annotator mask\n",
    "\n",
    "    if mode == \"union\":\n",
    "        merged = np.bitwise_or.reduce(arrs)\n",
    "    elif mode == \"majority\":\n",
    "        thr = (len(arrs) + 1) // 2       # majority among remaining annotators\n",
    "        merged = (np.sum(arrs, axis=0) >= thr).astype(int)\n",
    "    else:                                # \"intersection\"\n",
    "        merged = np.bitwise_and.reduce(arrs)\n",
    "    return merged.tolist()\n",
    "\n",
    "\n",
    "\n",
    "### --------- NEW VERSION ONLY CONSIDERS HATESPEECH --------- ###\n",
    "\n",
    "\n",
    "def preprocess_record(post):\n",
    "    text = \" \".join(post[\"post_tokens\"])\n",
    "    labels = [ann[\"label\"] for ann in post[\"annotators\"]]\n",
    "    majority_label = Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "    # Skip \"offensive\" posts entirely\n",
    "    if majority_label == \"offensive\":\n",
    "        return None\n",
    "\n",
    "    n_tokens = len(post[\"post_tokens\"])\n",
    "    merged_rat = None\n",
    "\n",
    "    if majority_label == \"hatespeech\" and post.get(\"rationales\"):\n",
    "        merged_rat = merge_rationales(post[\"rationales\"], n_tokens, mode=MERGE_MODE)\n",
    "\n",
    "    bin_label = \"toxic\" if majority_label == \"hatespeech\" else \"non-toxic\"\n",
    "    return text, bin_label, merged_rat\n",
    "\n",
    "records = {pid: preprocess_record(post) for pid, post in dataset.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data_binary: 15430\n",
      "this nigger just saved the uk\n"
     ]
    }
   ],
   "source": [
    "# combine hatespeech and offensive as toxic non-toxic\n",
    "\n",
    "\n",
    "data_binary = [\n",
    "    (text, \"toxic\") if label == \"hatespeech\" else (text, \"non-toxic\")\n",
    "    for text, label in resolved_examples_custom\n",
    "    if label in {\"hatespeech\", \"normal\"}\n",
    "]\n",
    "\n",
    "CKPT_DIR = \"../Models/hardkuma_ckpt\"\n",
    "\n",
    "\n",
    "print(f\"length of data_binary: {len(data_binary)}\")\n",
    "print(data_binary[106][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of toxic posts: 7616\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTION OF DATA LABELED AS TOXIC\n",
    "\n",
    "\n",
    "toxic_data = [post for post, label in data_binary if label == \"toxic\"]\n",
    "\n",
    "print(f\"Number of toxic posts: {len(toxic_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the HardKuma architecture has 2 tightly-coupled parts trained jointly:\n",
    "\n",
    "- Generator: Pick a minimal set of tokens that makes the text look toxic.\n",
    "- Predictor: Decide whether a post is toxic given only those selected tokens.\n",
    "\n",
    "Need to train this model also using non-toxic content even if the model is only used to predict rationales on toxic data at inference time, otherwise:\n",
    "- the predictor will be blocked thinking \"everything is toxic\" so the generator receives no pressure to isolate trigger words\n",
    "- since the predictor is happy regardless, length vs. continuity regularisers fight each other => get masks that highlight nothing (all 0s) or everything (all 1s)\n",
    "- the model never saw what non-toxic language looks like, so any unfamiliar wording might be (falsely) highlighted => poor generalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARDKUMA\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# HardKuma distribution utilities (Bastings et al., 2020)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "class HardKumaSampler(nn.Module):\n",
    "    \"\"\"Samples a binary (0/1) mask via the HardKuma reâ€‘parameterisation.\n",
    "\n",
    "    Given shape (alpha) and rate (beta) > 0, the sampler draws a sample z in\n",
    "    the open interval (0, 1) during the forward pass, then hardâ€‘rounds it to\n",
    "    {0,1} while using the soft value for gradient flow (straightâ€‘through).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, alpha: torch.Tensor, beta: torch.Tensor, hard: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Return (z_hard, z_soft).\n",
    "\n",
    "        z_soft is the continuous sample; z_hard is detached to be exactly 0/1\n",
    "        but uses z_soft in the backward pass (straightâ€‘through).\n",
    "        \"\"\"\n",
    "        # Sample u ~ Uniform(0, 1)\n",
    "        u = torch.rand_like(alpha)\n",
    "        v = (1 - u.pow(1.0 / beta)).clamp(self.eps, 1 - self.eps)\n",
    "        z_soft = (1 - v.pow(1.0 / alpha)).clamp(self.eps, 1 - self.eps)\n",
    "\n",
    "        if hard:\n",
    "            z_hard = (z_soft > 0.5).float()\n",
    "            # Straightâ€‘through gradient: replace hard with soft in backward\n",
    "            z_hard = z_hard.detach() - z_soft.detach() + z_soft\n",
    "        else:\n",
    "            z_hard = z_soft\n",
    "        return z_hard, z_soft\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Rationale Generator + Predictor model\n",
    "# -------------------------------------------------------------\n",
    "class HardKumaRationaleModel(nn.Module):\n",
    "    \"\"\"Generatorâ€‘Predictor architecture for rationale extraction.\n",
    "\n",
    "    * Generator: produces binary mask z over tokens via HardKuma.\n",
    "    * Predictor: applies BERT to the masked input and predicts toxicity.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert_name: str = \"bert-base-uncased\", max_len: int = 128):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.bert = AutoModel.from_pretrained(bert_name)\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # Generator head â†’ 2 positives (alpha, beta) per token\n",
    "        self.gen_head = nn.Linear(hidden_size, 2)\n",
    "        self.hardkuma = HardKumaSampler()\n",
    "\n",
    "        # Classifier head on [CLS]\n",
    "        self.cls_head = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Mask application helper\n",
    "    # ------------------------------------------------------------------\n",
    "    @staticmethod\n",
    "    def apply_mask(embeddings: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Elementâ€‘wise multiply embeddings by z (shape: batch Ã— seq_len Ã— 1).\"\"\"\n",
    "        return embeddings * z.unsqueeze(-1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        rationale_labels: Optional[torch.Tensor] = None,\n",
    "        lambda_len: float = 1.0,\n",
    "        lambda_cont: float = 1.0,\n",
    "        lambda_sup: float = 1.0,\n",
    "    ) -> dict:\n",
    "        # BERT contextual embeddings\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        hidden = outputs.last_hidden_state  # (B, L, H)\n",
    "\n",
    "        # Generator: predict alpha, beta > 0 via softplus\n",
    "        alpha_beta = F.softplus(self.gen_head(hidden)) + 1e-4  # (B, L, 2)\n",
    "        alpha, beta = alpha_beta[..., 0], alpha_beta[..., 1]\n",
    "\n",
    "        z, z_soft = self.hardkuma(alpha, beta)  # (B, L)\n",
    "        masked_hidden = self.apply_mask(hidden, z)\n",
    "\n",
    "        # Predictor on masked sequence (take [CLS])\n",
    "        cls_repr = masked_hidden[:, 0, :]\n",
    "        logits = self.cls_head(cls_repr).squeeze(-1)  # (B,)\n",
    "\n",
    "        # ----------------------------------------------------------\n",
    "        # Loss components\n",
    "        # ----------------------------------------------------------\n",
    "        out = {\"logits\": logits, \"z_hard\": z, \"z_soft\": z_soft}\n",
    "\n",
    "        if rationale_labels is not None:\n",
    "            # Binary crossâ€‘entropy for token supervision\n",
    "            sup_loss = F.binary_cross_entropy(z_soft, rationale_labels.float(), reduction=\"none\")\n",
    "            sup_loss = (sup_loss * attention_mask).sum() / attention_mask.sum()\n",
    "            out[\"sup_loss\"] = sup_loss * lambda_sup\n",
    "        else:\n",
    "            out[\"sup_loss\"] = 0.0 * logits.sum()\n",
    "\n",
    "        # Length regulariser: encourage sparse mask\n",
    "        avg_len = z_soft.mean()\n",
    "        len_loss = avg_len * lambda_len\n",
    "        out[\"len_loss\"] = len_loss\n",
    "\n",
    "        # Continuity regulariser: encourage contiguous spans\n",
    "        diff = torch.abs(z_soft[:, 1:] - z_soft[:, :-1]) * attention_mask[:, 1:]\n",
    "        cont_loss = diff.mean() * lambda_cont\n",
    "        out[\"cont_loss\"] = cont_loss\n",
    "\n",
    "        # Classification loss must be computed outside (BCEWithLogitsLoss)\n",
    "        return out\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Training step utility\n",
    "# -------------------------------------------------------------\n",
    "def training_step(batch, model, criterion, lambdas):\n",
    "    # unpack & move to device\n",
    "    input_ids, attn_mask, labels, rat_labels = (t.to(DEVICE) for t in batch)\n",
    "\n",
    "    out = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attn_mask,\n",
    "        rationale_labels=rat_labels,\n",
    "        lambda_len=lambdas[\"len\"],\n",
    "        lambda_cont=lambdas[\"cont\"],\n",
    "        lambda_sup=lambdas[\"sup\"],\n",
    "    )\n",
    "\n",
    "    sup_loss_raw = out[\"sup_loss\"]                     # (scalar per sample)\n",
    "    has_mask     = (rat_labels.sum(dim=1) > 0).float()\n",
    "    sup_loss     = (sup_loss_raw * has_mask).sum() / has_mask.sum().clamp(min=1)\n",
    "\n",
    "    clf_loss   = criterion(out[\"logits\"], labels)\n",
    "    total_loss = clf_loss + sup_loss + out[\"len_loss\"] + out[\"cont_loss\"]\n",
    "    out.update({\"clf_loss\": clf_loss, \"total_loss\": total_loss})\n",
    "\n",
    "    # Cast labels to int **once** for metric calculation later\n",
    "    labels_long = labels.long()\n",
    "    return out, labels_long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bert-base-uncased is a pretrained transformer model published in the original BERT paper (uncased = converts all input text to lowercase + removes accents and casing distinctions) --> fast tokenisers, mature implementations, and widespread usage in toxic content classification benchmarks + Matches the token distribution in HateXplain\n",
    "\n",
    "/!\\ HateBERT only if targeting in-domain toxic slang, especially from Reddit or Gab but may overfit to source domain (less general) /!\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset wrapper\n",
    "\n",
    "class HateXplainDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item from `data_binary` is a (text, label_str) tuple where\n",
    "        label_str âˆˆ {\"toxic\", \"non-toxic\"}.\n",
    "    Optionally supply `rat_masks` - a list (same length) where each element is\n",
    "    either:\n",
    "        * list[int] of 0/1 at **word** level  (toxic post with annotation)\n",
    "        * None                                (toxic post w/out annot OR non-toxic)\n",
    "    The class:\n",
    "        â€¢ tokenises with HF tokenizer\n",
    "        â€¢ aligns word-level rationale to WordPiece level\n",
    "        â€¢ outputs (input_ids, attention_mask, label_float, rat_mask, sup_weight)\n",
    "    \"\"\"\n",
    "\n",
    "    LABEL_MAP = {\"non-toxic\": 0.0, \"toxic\": 1.0}\n",
    "\n",
    "    def __init__(self, pairs, ratm, tokenizer, max_len):\n",
    "        self.pairs, self.ratm = pairs, ratm\n",
    "        self.tok, self.max_len = tokenizer, max_len\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, lbl = self.pairs[idx]\n",
    "        label = torch.tensor(self.LABEL_MAP[lbl])\n",
    "        enc = self.tok(text, truncation=True, padding=\"max_length\",\n",
    "                       max_length=self.max_len, return_offsets_mapping=True,\n",
    "                       return_tensors=\"pt\")\n",
    "        ids  = enc[\"input_ids\"].squeeze(0)\n",
    "        attn = enc[\"attention_mask\"].squeeze(0)\n",
    "        offs = enc[\"offset_mapping\"].squeeze(0)\n",
    "\n",
    "        # ----- build rationale mask -----\n",
    "        if self.ratm[idx] is not None:            # toxic with annotation\n",
    "            word_mask = torch.tensor(self.ratm[idx], dtype=torch.float)\n",
    "            wp2word = (offs[:,0]==0).cumsum(0)-1\n",
    "            wp2word[wp2word < 0] = -1\n",
    "            wp2word[wp2word >= len(word_mask)] = -1\n",
    "            sel   = wp2word >= 0\n",
    "            rmask = torch.zeros_like(ids, dtype=torch.float)\n",
    "            rmask[sel] = word_mask[wp2word[sel]]\n",
    "        else:\n",
    "            rmask = torch.zeros_like(ids, dtype=torch.float)\n",
    "\n",
    "        return ids, attn, label, rmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data -> train / val + test set\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "records = {pid: out for pid, post in dataset.items()\n",
    "           if (out := preprocess_record(post)) is not None} # we skip posts that were removed due to 'offensive'\n",
    "\n",
    "def make_subset(id_list):\n",
    "    texts, labels, ratm = [], [], []\n",
    "    for pid in id_list:\n",
    "        if pid not in records:\n",
    "            continue  # skip posts that were removed due to 'offensive'\n",
    "        text, lab, rat = records[pid]\n",
    "        texts.append(text)\n",
    "        labels.append(lab)\n",
    "        ratm.append(rat)\n",
    "    return list(zip(texts, labels)), ratm\n",
    "\n",
    "\n",
    "train_pairs, train_rats = make_subset(split_ids[\"train\"])\n",
    "valid_pairs, valid_rats = make_subset(split_ids[\"val\"])\n",
    "test_pairs, test_rats = make_subset(split_ids[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution: Counter({'non-toxic': 6251, 'toxic': 4748})\n",
      "Valid label distribution: Counter({'non-toxic': 781, 'toxic': 593})\n",
      "Test  label distribution: Counter({'non-toxic': 782, 'toxic': 594})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Train label distribution:\", Counter([label for _, label in train_pairs]))\n",
    "print(\"Valid label distribution:\", Counter([label for _, label in valid_pairs]))\n",
    "print(\"Test  label distribution:\", Counter([label for _, label in test_pairs]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10999, 1374, 1376)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs), len(valid_pairs), len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    return tuple(torch.stack(items) for items in zip(*batch))\n",
    "\n",
    "BATCH_SZ = 16\n",
    "MAX_LEN = 128\n",
    "\n",
    "train_ds = HateXplainDataset(train_pairs, train_rats, tokenizer, MAX_LEN)\n",
    "val_ds   = HateXplainDataset(valid_pairs,  valid_rats,  tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SZ,\n",
    "                          shuffle=True,  collate_fn=collate)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SZ,\n",
    "                          shuffle=False, collate_fn=collate)\n",
    "\n",
    "\n",
    "\n",
    "model = HardKumaRationaleModel(max_len=MAX_LEN).to(DEVICE)\n",
    "\n",
    "pos_weight = torch.tensor([len([l for _,l in train_pairs if l==\"non-toxic\"]) /\n",
    "                      len([l for _,l in train_pairs if l==\"toxic\"])],\n",
    "                     device=DEVICE) # to balance classes -> class weight\n",
    "clf_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "lambdas = {\"len\": 3.0,  # stronger sparsity -> TUNE!!!!\n",
    "           \"cont\": 2.0,\n",
    "           \"sup\": 1.0}   # set to 0 if no supervised labels at all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rationales in generated data using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HardKumaRationaleModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (gen_head): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (hardkuma): HardKumaSampler()\n",
       "  (cls_head): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD MODEL\n",
    "\n",
    "# 3.1  Rebuild tokenizer exactly as before\n",
    "\n",
    "CKPT_DIR = \"../Models/hardkuma_ckpt\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CKPT_DIR)\n",
    "\n",
    "# 3.2  Read metadata, recreate the architecture skeleton\n",
    "meta  = json.load(open(f\"{CKPT_DIR}/training_meta.json\"))\n",
    "model = HardKumaRationaleModel(\n",
    "            bert_name = meta[\"bert_model_name\"],\n",
    "            max_len   = meta[\"max_len\"]\n",
    "        )\n",
    "model.load_state_dict(torch.load(f\"{CKPT_DIR}/pytorch_model.bin\",\n",
    "                                 map_location=DEVICE))\n",
    "model.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# load generated data\n",
    "\n",
    "toxic_path = \"../augmented_data/combined-toxic.csv\"\n",
    "generated_toxic_posts = pd.read_csv(toxic_path)[\"text\"].tolist()\n",
    "\n",
    "non_toxic_path = \"../augmented_data/combined-non-toxic.csv\" \n",
    "generated_non_toxic_posts = pd.read_csv(non_toxic_path)[\"text\"].tolist()\n",
    "\n",
    "print(len(generated_toxic_posts))\n",
    "print(len(generated_non_toxic_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rationales(texts, model, tokenizer, max_len=128, batch_size=16):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        texts      : List[str] toxic posts (e.g. from CSV)\n",
    "        model      : trained HardKumaRationaleModel (already loaded and .eval())\n",
    "        tokenizer  : tokenizer matching the model\n",
    "        max_len    : max token length (same as used during training)\n",
    "        batch_size : batch size for inference\n",
    "\n",
    "    Returns:\n",
    "        List[Dict] â€” for each text:\n",
    "            {\n",
    "              'tokens':            List[str] (WordPiece tokens),\n",
    "              'rationale_mask':    List[int] (0/1, aligned with tokens),\n",
    "              'rationale_tokens':  List[str] (non-special tokens where mask == 1)\n",
    "            }\n",
    "    \"\"\"\n",
    "     # -- dataset: wrap each string with a dummy \"toxic\" label\n",
    "    dataset = HateXplainDataset(\n",
    "                [(t, \"toxic\") for t in texts],   # pairs (text, label)\n",
    "                ratm=[None] * len(texts),        # no human rationales\n",
    "                tokenizer=tokenizer,\n",
    "                max_len=max_len\n",
    "             )\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=collate)\n",
    "\n",
    "    results = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ids, attn, _, _ in loader:           # 4-tuple per collate\n",
    "            ids, attn = ids.to(DEVICE), attn.to(DEVICE)\n",
    "            z_hard    = model(ids, attn)[\"z_hard\"].cpu()   # (B, L)\n",
    "\n",
    "            for wp_ids, wp_mask, z in zip(ids.cpu(),\n",
    "                                          attn.cpu(),\n",
    "                                          z_hard):\n",
    "                tokens = tokenizer.convert_ids_to_tokens(wp_ids.tolist())\n",
    "                rationale_tokens = [\n",
    "                    tok for tok, m, zh in zip(tokens, wp_mask, z)\n",
    "                    if m == 1 and zh == 1\n",
    "                       and tok not in (\"[CLS]\", \"[SEP]\", \"[PAD]\")\n",
    "                ]\n",
    "                results.append(\n",
    "                    dict(tokens=tokens,\n",
    "                         rationale_mask=z.int().tolist(),\n",
    "                         rationale_tokens=rationale_tokens)\n",
    "                )\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rationale_outputs = find_rationales(generated_toxic_posts, model=model, tokenizer=tokenizer, max_len=128 , batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homoglyph / leet substitution on rationales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because rationale_mask aligns 1-to-1 with WordPiece tokens, you can now:\n",
    "\n",
    "1) reconstruct each contiguous span (idi ##0 ##t â†’ idi0t),\n",
    "\n",
    "2) substitute only those spans with your homoglyph/leet mapping,\n",
    "\n",
    "3) re-join the sentence (keeping everything else intact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn generated posts into the same â€œpair + maskâ€ format\n",
    "\n",
    "# 2.1  toxic\n",
    "gen_tox_pairs = [(text, \"toxic\") for text in generated_toxic_posts]\n",
    "gen_tox_rats  = [out[\"rationale_mask\"] for out in rationale_outputs]\n",
    "\n",
    "# 2.2  non-toxic  (mask = None â†’ will become zeros)\n",
    "gen_nontox_pairs = [(t, \"non-toxic\") for t in generated_non_toxic_posts]\n",
    "gen_nontox_rats  = [None] * len(gen_nontox_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376\n",
      "1376\n"
     ]
    }
   ],
   "source": [
    "# split generated data 8:1:1 and merge with original splits\n",
    "\n",
    "def split(lst, rats, train_p=0.8, val_p=0.1):\n",
    "    idx = np.random.permutation(len(lst))\n",
    "    n_train = int(train_p*len(lst)); n_val = int(val_p*len(lst))\n",
    "    tr, va, te = idx[:n_train], idx[n_train:n_train+n_val], idx[n_train+n_val:]\n",
    "    return ([lst[i] for i in tr], [rats[i] for i in tr],\n",
    "            [lst[i] for i in va], [rats[i] for i in va],\n",
    "            [lst[i] for i in te], [rats[i] for i in te])\n",
    "\n",
    "(t_tr, r_tr, t_va, r_va, t_te, r_te) = split(gen_tox_pairs, gen_tox_rats, 1.0)\n",
    "(nt_tr, nr_tr, nt_va, nr_va, nt_te, nr_te) = split(gen_nontox_pairs, gen_nontox_rats, 1.0)\n",
    "\n",
    "print(len(test_pairs))\n",
    "\n",
    "train_pairs += t_tr + nt_tr;    train_rats += r_tr + nr_tr\n",
    "valid_pairs += t_va + nt_va;    valid_rats += r_va + nr_va\n",
    "test_pairs  += t_te + nt_te;    test_rats  += r_te + nr_te\n",
    "\n",
    "print(len(test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_homoglyph_map():\n",
    "    url = \"https://www.unicode.org/Public/security/latest/confusables.txt\" \n",
    "    response = requests.get(url) # Fetch the confusables data\n",
    "    raw_text = response.text     # Get the text content\n",
    "\n",
    "    homoglyph_map = defaultdict(list) \n",
    "\n",
    "    for line in raw_text.splitlines():\n",
    "        if line.startswith('#') or not line.strip(): # Skip comments and empty lines\n",
    "            continue\n",
    "        try:\n",
    "            src_hex, target_hex, *_ = line.split(';') # \n",
    "            src_char = chr(int(src_hex.strip(), 16))\n",
    "            target_chars = ''.join([chr(int(h, 16)) for h in target_hex.strip().split()])\n",
    "\n",
    "            # We only want visually similar substitutions that map to 1 character\n",
    "            if len(src_char) == 1 and len(target_chars) == 1:\n",
    "                ascii_base = target_chars.lower()\n",
    "                if ascii_base.isascii() and ascii_base.isalnum():\n",
    "                    homoglyph_map[ascii_base].append(src_char)\n",
    "        except Exception as e:\n",
    "            continue  # skip malformed lines\n",
    "\n",
    "    # Convert defaultdict to normal dict and deduplicate entries\n",
    "    homoglyph_map = {k: list(set(v)) for k, v in homoglyph_map.items()}\n",
    "\n",
    "    return homoglyph_map\n",
    "\n",
    "# 0.2  simple leet converter (stub)\n",
    "class SimpleLeeter:\n",
    "    _map = str.maketrans(\"aeios\", \"43105\")  # toy map, replace with yours\n",
    "    def text2leet(self, word): return word.translate(self._map)\n",
    "\n",
    "random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1  convert rationale_tokens list âžœ target_words set (lower-case)\n",
    "def toks_to_wordset(tok_list):\n",
    "    return set(t.lower() for t in tok_list)\n",
    "\n",
    "# 1.2  make HateXplain-style record\n",
    "def make_record(text, label_str, rat_mask=None):\n",
    "    return (text, label_str), rat_mask\n",
    "\n",
    "def perturb_token(token, homoglyph_map, leeter, mode):\n",
    "    # strip ## for sub-words, re-attach later\n",
    "    prefix = \"##\" if token.startswith(\"##\") else \"\"\n",
    "    core   = token[2:] if prefix else token\n",
    "\n",
    "    if mode in (\"homoglyph\", \"both\"):\n",
    "        core = ''.join(\n",
    "            random.choice(homoglyph_map[c]) if c in homoglyph_map and random.random()<0.5 else c\n",
    "            for c in core\n",
    "        )\n",
    "    if mode in (\"leet\", \"both\"):\n",
    "        core = leeter.text2leet(core)\n",
    "    return prefix + core\n",
    "\n",
    "def random_homoglyph_substitution(text, homoglyph_map, prob=0.4):\n",
    "    new_text = \"\"\n",
    "    for char in text:\n",
    "        if char.isalpha() and char.lower() in homoglyph_map and random.random() < prob:\n",
    "            replacement = random.choice(homoglyph_map[char.lower()])\n",
    "            new_text += replacement\n",
    "        else:\n",
    "            new_text += char\n",
    "    return new_text\n",
    "\n",
    "def smart_homoglyph_substitution(text, homoglyph_map, target_words, prob=0.5):\n",
    "    tokens = text.split()\n",
    "    new_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if any(word in token.lower() for word in target_words) and random.random() < prob:\n",
    "            new_token = ''.join(\n",
    "                random.choice(homoglyph_map[c.lower()]) if c.lower() in homoglyph_map and random.random() < 0.5 else c\n",
    "                for c in token\n",
    "            )\n",
    "            new_tokens.append(new_token)\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "\n",
    "    return ' '.join(new_tokens)\n",
    "\n",
    "def leet_some_words(text, leeter, word_prob=0.6):\n",
    "    \"\"\"\n",
    "    Randomly leet some words in the text based on a probability.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if random.random() < word_prob:\n",
    "            new_words.append(leeter.text2leet(word))\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def augment_text(text, leeter, homoglyph_map, target_words=None):\n",
    "    mode = random.choice([\"leet\", \"homoglyph\", \"both\"])\n",
    "\n",
    "    if mode == \"leet\":\n",
    "        text = leet_some_words(text, leeter)\n",
    "    elif mode == \"homoglyph\":\n",
    "        text = smart_homoglyph_substitution(text, homoglyph_map, target_words or [])\n",
    "    elif mode == \"both\":\n",
    "        text = leet_some_words(text, leeter)\n",
    "        text = smart_homoglyph_substitution(text, homoglyph_map, target_words or [])\n",
    "    # mode == \"none\": return as is\n",
    "    return text\n",
    "\n",
    "def augment_tokens(tokens, mask, homoglyph_map, leeter, p_apply=0.8):\n",
    "    \"\"\"\n",
    "    tokens: list[str] WordPiece\n",
    "    mask  : list[int] 0/1 aligned (None â†’ treat as all zeros)\n",
    "    \"\"\"\n",
    "    if mask is None or random.random() > p_apply:\n",
    "        return tokenizer.convert_tokens_to_string(tokens)   # leave unchanged\n",
    "\n",
    "    mode = random.choice([\"homoglyph\", \"leet\", \"both\"])\n",
    "    new_tokens = [\n",
    "        perturb_token(tok, homoglyph_map, leeter, mode) if m==1 else tok\n",
    "        for tok, m in zip(tokens, mask)\n",
    "    ]\n",
    "    return tokenizer.convert_tokens_to_string(new_tokens)\n",
    "\n",
    "def build_augmented_texts(pairs, rats, tokenizer, homoglyph_map, leeter):\n",
    "    aug_texts, aug_labels = [], []\n",
    "    for (txt, lab), mask in zip(pairs, rats):\n",
    "        # tokenize original because rats is word-level for original splits\n",
    "        if mask is not None and isinstance(mask[0], int):           # word-level?\n",
    "            ids = tokenizer(txt, add_special_tokens=True)[\"input_ids\"]\n",
    "            tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "            # For original data, we already aligned rat_mask to WordPiece earlier\n",
    "            wp_mask = mask                                           \n",
    "        else:   # for generated tox we already have WordPiece tokens\n",
    "            tokens  = tokenizer.tokenize(txt)\n",
    "            wp_mask = mask if mask is not None else [0]*len(tokens)\n",
    "\n",
    "        augmented = augment_tokens(tokens, wp_mask,\n",
    "                                   homoglyph_map, leeter)\n",
    "        aug_texts.append(augmented); aug_labels.append(lab)\n",
    "    return aug_texts, aug_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "homoglyph_map = build_homoglyph_map()\n",
    "leeter = SimpleLeeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set distribution after reassignment:\n",
      " non-toxic: 782\n",
      "     toxic: 594\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def partial_augment(pairs, rats, tokenizer, homoglyph_map, leeter, frac=0.2):\n",
    "    # Select 30% of the data to augment\n",
    "    indices = random.sample(range(len(pairs)), int(len(pairs) * frac))\n",
    "    selected_pairs = [pairs[i] for i in indices]\n",
    "    selected_rats  = [rats[i]  for i in indices]\n",
    "\n",
    "    aug_texts, aug_labels = build_augmented_texts(selected_pairs, selected_rats, tokenizer, homoglyph_map, leeter)\n",
    "\n",
    "    # Combine original data + augmented samples\n",
    "    orig_texts  = [txt for (txt, _), _ in zip(pairs, rats)]\n",
    "    orig_labels = [lab for (_, lab), _ in zip(pairs, rats)]\n",
    "\n",
    "    all_texts  = orig_texts + aug_texts\n",
    "    all_labels = orig_labels + aug_labels\n",
    "    return all_texts, all_labels\n",
    "\n",
    "# 30% augmentation of each split\n",
    "train_aug, train_lab = partial_augment(train_pairs,   train_rats,   tokenizer, homoglyph_map, leeter, frac=0.2)\n",
    "valid_aug,   valid_lab   = partial_augment(valid_pairs,   valid_rats,   tokenizer, homoglyph_map, leeter, frac=0.2)\n",
    "\n",
    "# No augmentation of test \n",
    "test_aug, test_lab = test_pairs,  test_rats\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Get labels from test_aug\n",
    "test_labels = [label for _, label in test_aug]\n",
    "\n",
    "# Print label distribution\n",
    "print(\"Test set distribution after reassignment:\")\n",
    "for label, count in Counter(test_labels).items():\n",
    "    print(f\"{label:>10}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sizes:\n",
      "  train  : 14487\n",
      "  valid  : 1648\n",
      "  test   : 1376\n",
      "Train distribution:\n",
      "   non-toxic: 6707\n",
      "       toxic: 5366\n",
      "\n",
      "Validation distribution:\n",
      "   non-toxic: 781\n",
      "       toxic: 593\n",
      "\n",
      "Test distribution:\n",
      "   non-toxic: 782\n",
      "       toxic: 594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aug_train_pairs = list(zip(train_aug, train_lab))\n",
    "aug_valid_pairs = list(zip(valid_aug, valid_lab))\n",
    "aug_test_pairs  = list(zip(test_aug,  test_lab))\n",
    "\n",
    "# rat_masks stay identical to originals for HardKuma supervision\n",
    "aug_train_rats, aug_valid_rats, aug_test_rats = train_rats, valid_rats, test_rats\n",
    "\n",
    "\n",
    "print(f\"Final sizes:\\n\"\n",
    "      f\"  train  : {len(aug_train_pairs)}\\n\"\n",
    "      f\"  valid  : {len(aug_valid_pairs)}\\n\"\n",
    "      f\"  test   : {len(aug_test_pairs)}\")\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def print_label_distribution(pairs, name):\n",
    "    labels = [label for _, label in pairs]\n",
    "    dist = Counter(labels)\n",
    "    print(f\"{name} distribution:\")\n",
    "    for label, count in dist.items():\n",
    "        print(f\"  {label:>10}: {count}\")\n",
    "    print()\n",
    "\n",
    "print_label_distribution(train_pairs, \"Train\")\n",
    "print_label_distribution(valid_pairs, \"Validation\")\n",
    "print_label_distribution(test_pairs,  \"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FINE-TUNING WITH AUGMENTED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test label distribution: Counter({0: 782, 1: 594})\n",
      "Valid label distribution: Counter({0: 931, 1: 717})\n",
      "Train label distribution Counter({0: 8047, 1: 6440})\n"
     ]
    }
   ],
   "source": [
    "# tokenize the augmented dataset and turn them into torch dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tum-nlp/bert-hateXplain\")\n",
    "\n",
    "def encode_texts(texts, labels):\n",
    "    enc = tokenizer(texts,\n",
    "                    padding='longest',        # dynamic pad per batch\n",
    "                    truncation=True,\n",
    "                    max_length=128)\n",
    "    enc[\"labels\"] = labels\n",
    "    return enc\n",
    "\n",
    "\n",
    "# Unpack text and label from augmented pairs\n",
    "train_aug, train_lab = zip(*aug_train_pairs)\n",
    "valid_aug, valid_lab = zip(*aug_valid_pairs)\n",
    "test_aug,  test_lab  = zip(*test_pairs)\n",
    "\n",
    "# Recreate binary label lists for each split\n",
    "train_labels = [1 if l == \"toxic\" else 0 for l in train_lab]\n",
    "val_labels   = [1 if l == \"toxic\" else 0 for l in valid_lab]\n",
    "test_labels  = [1 if l == \"toxic\" else 0 for l in test_lab]\n",
    "\n",
    "train_texts = train_aug\n",
    "val_texts   = valid_aug\n",
    "test_texts  = test_aug\n",
    "\n",
    "\n",
    "print(\"Test label distribution:\", Counter(test_labels))\n",
    "print(\"Valid label distribution:\", Counter(val_labels))\n",
    "print(\"Train label distribution\", Counter(train_labels))\n",
    "\n",
    "\n",
    "train_tokenized = encode_texts(train_texts, train_labels)\n",
    "val_tokenized   = encode_texts(val_texts,   val_labels)\n",
    "test_tokenized  = encode_texts(test_texts,  test_labels)\n",
    "\n",
    "\n",
    "class TorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, enc):\n",
    "        self.enc = enc\n",
    "    def __len__(self):\n",
    "        return len(self.enc[\"input_ids\"])\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: torch.tensor(v[idx]) for k, v in self.enc.items()}\n",
    "\n",
    "train_ds = TorchDataset(train_tokenized)\n",
    "val_ds   = TorchDataset(val_tokenized)\n",
    "test_ds  = TorchDataset(test_tokenized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\")\n",
    "    f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc,\n",
    "            \"f1_macro\": f1_macro,\n",
    "            \"f1_weighted\": f1_weighted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52.3\n",
      "Transformers path: /home/venvs/leetspeak-env2/lib/python3.12/site-packages/transformers/__init__.py\n",
      "TrainingArguments from: transformers.training_args\n",
      "TrainingArguments class: <class 'transformers.training_args.TrainingArguments'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4530' max='9060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4530/9060 02:06 < 02:07, 35.65 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.450700</td>\n",
       "      <td>0.415685</td>\n",
       "      <td>0.873180</td>\n",
       "      <td>0.871379</td>\n",
       "      <td>0.873355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.359800</td>\n",
       "      <td>0.428610</td>\n",
       "      <td>0.858617</td>\n",
       "      <td>0.857995</td>\n",
       "      <td>0.859215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>0.413789</td>\n",
       "      <td>0.881675</td>\n",
       "      <td>0.880356</td>\n",
       "      <td>0.881987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.308800</td>\n",
       "      <td>0.427516</td>\n",
       "      <td>0.884102</td>\n",
       "      <td>0.882490</td>\n",
       "      <td>0.884277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.432372</td>\n",
       "      <td>0.879854</td>\n",
       "      <td>0.878531</td>\n",
       "      <td>0.880177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: ./results/checkpoint-2718\n"
     ]
    }
   ],
   "source": [
    "# Trainer setup\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"tum-nlp/bert-hateXplain\",\n",
    "            num_labels=2,\n",
    "            use_safetensors=True       # <- tells HF to load the .safetensors\n",
    ")\n",
    "\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "print(\"Transformers path:\", transformers.__file__)\n",
    "from transformers import TrainingArguments\n",
    "print(\"TrainingArguments from:\", TrainingArguments.__module__)\n",
    "print(\"TrainingArguments class:\", TrainingArguments)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    label_smoothing_factor=0.1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=1,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model         = model,\n",
    "    args          = training_args,\n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset  = val_ds,\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks     = [EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"Best checkpoint:\", trainer.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap train-test: 2\n"
     ]
    }
   ],
   "source": [
    "train_texts = set([t for t, _ in train_pairs])\n",
    "test_texts  = set([t for t, _ in test_pairs])\n",
    "overlap = train_texts.intersection(test_texts)\n",
    "print(f\"Overlap train-test: {len(overlap)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.42699116468429565, 'test_accuracy': 0.8677325581395349, 'test_f1_macro': 0.8660986209492523, 'test_f1_weighted': 0.8681195432635492, 'test_runtime': 1.1095, 'test_samples_per_second': 1240.239, 'test_steps_per_second': 155.03, 'epoch': 5.0}\n",
      "1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert-hateXplain-aug-finetuned/tokenizer_config.json',\n",
       " 'bert-hateXplain-aug-finetuned/special_tokens_map.json',\n",
       " 'bert-hateXplain-aug-finetuned/vocab.txt',\n",
       " 'bert-hateXplain-aug-finetuned/added_tokens.json',\n",
       " 'bert-hateXplain-aug-finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "test_results = trainer.evaluate(test_ds, metric_key_prefix=\"test\")\n",
    "print(test_results)\n",
    "\n",
    "print(len(test_ds))\n",
    "\n",
    "# Save model & tokenizer\n",
    "save_dir = \"../Models/bert-hateXplain-aug-finetuned\"\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (leetspeak-env2)",
   "language": "python",
   "name": "leetspeak-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
